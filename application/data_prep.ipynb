{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pyresample.geometry import AreaDefinition\n",
    "from pyresample.geometry import SwathDefinition\n",
    "from pyresample import kd_tree\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pyreadr\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\")) # to import from parent directory\n",
    "from evaluation.metrics import *\n",
    "from utils import gev2frech\n",
    "import cmcrameri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data\n",
    "\n",
    "This section transforms the raw data from DWD to a lat,lon projection and interpolates the grid to the specified area across Western Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/application/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define original area\n",
    "projection = \"+proj=lcc +lat_1=35 +lat_2=65 +lat_0=52 +lon_0=10 +x_0=4000000 +y_0=2800000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"\n",
    "width = 1200\n",
    "height = 1100\n",
    "area_extent = (3500000, 2100000, 4700000, 3200000)\n",
    "area_def = AreaDefinition('original', 'Original grid', 'id', projection,width, height, area_extent)\n",
    "\n",
    "# Define target grid\n",
    "lons = np.linspace(6.38,7.48,30)\n",
    "lats = np.linspace(50.27,50.97,30)\n",
    "lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "target_grid = SwathDefinition(lons = lon2d, lats = lat2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for projection, interpolation and monthly maximum\n",
    "def downsample(data, area_def, target_grid):\n",
    "    result = kd_tree.resample_nearest(\n",
    "        area_def, data, target_grid, radius_of_influence=50000, epsilon=0.5\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def xr_downsample(data, area_def, target_grid):\n",
    "    result = xr.apply_ufunc(\n",
    "        downsample,\n",
    "        data,\n",
    "        area_def,\n",
    "        target_grid,\n",
    "        input_core_dims=[[\"y\", \"x\", \"time\"], [], []],\n",
    "        output_core_dims=[[\"y\", \"x\", \"time\"]],\n",
    "        exclude_dims=set((\"x\", \"y\")),\n",
    "        vectorize = True,\n",
    "        dask = \"allowed\"\n",
    "    )\n",
    "    return result.max(dim = [\"time\"])\n",
    "\n",
    "def transform_data(data, area_def, target_grid, year = \"\"):\n",
    "    transformed_data = data.resample(time = \"1MS\").apply(xr_downsample, args = (area_def, target_grid))\n",
    "    transformed_data = transformed_data.isel(time=(transformed_data.time.dt.month.isin([6,7,8])))\n",
    "    xr.Dataset({\"pr\":transformed_data}).to_netcdf(f\"../../data/application/{year}_month_max.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'c:\\\\Users\\\\chris\\\\Desktop\\\\Forschung\\\\MA_paper\\\\code\\\\data\\\\application\\\\data\\\\1931_2020_raw.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key]\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[key]\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('c:\\\\Users\\\\chris\\\\Desktop\\\\Forschung\\\\MA_paper\\\\code\\\\data\\\\application\\\\data\\\\1931_2020_raw.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '14674a18-c561-4a8a-a1d4-126b5ed12bec']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1931_2020_raw.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m raw_data\u001b[38;5;241m.\u001b[39mpr\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39m(raw_data\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m])))\n\u001b[0;32m      4\u001b[0m transform_data(data, area_def, target_grid, year \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1931_2020\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\api.py:566\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[0;32m    555\u001b[0m     decode_cf,\n\u001b[0;32m    556\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 566\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[0;32m    567\u001b[0m     filename_or_obj,\n\u001b[0;32m    568\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    571\u001b[0m )\n\u001b[0;32m    572\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[0;32m    573\u001b[0m     backend_ds,\n\u001b[0;32m    574\u001b[0m     filename_or_obj,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    585\u001b[0m )\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:590\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[1;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    571\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    588\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[0;32m    589\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[1;32m--> 590\u001b[0m     store \u001b[38;5;241m=\u001b[39m NetCDF4DataStore\u001b[38;5;241m.\u001b[39mopen(\n\u001b[0;32m    591\u001b[0m         filename_or_obj,\n\u001b[0;32m    592\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    594\u001b[0m         group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m    595\u001b[0m         clobber\u001b[38;5;241m=\u001b[39mclobber,\n\u001b[0;32m    596\u001b[0m         diskless\u001b[38;5;241m=\u001b[39mdiskless,\n\u001b[0;32m    597\u001b[0m         persist\u001b[38;5;241m=\u001b[39mpersist,\n\u001b[0;32m    598\u001b[0m         lock\u001b[38;5;241m=\u001b[39mlock,\n\u001b[0;32m    599\u001b[0m         autoclose\u001b[38;5;241m=\u001b[39mautoclose,\n\u001b[0;32m    600\u001b[0m     )\n\u001b[0;32m    602\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:391\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[1;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[0;32m    385\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    386\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    387\u001b[0m )\n\u001b[0;32m    388\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[0;32m    389\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    390\u001b[0m )\n\u001b[1;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(manager, group\u001b[38;5;241m=\u001b[39mgroup, mode\u001b[38;5;241m=\u001b[39mmode, lock\u001b[38;5;241m=\u001b[39mlock, autoclose\u001b[38;5;241m=\u001b[39mautoclose)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:338\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[1;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:400\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire()\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:394\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m    395\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_with_cache_info(needs_lock)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ma\\Lib\\site-packages\\xarray\\backends\\file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32msrc\\netCDF4\\_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\netCDF4\\_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'c:\\\\Users\\\\chris\\\\Desktop\\\\Forschung\\\\MA_paper\\\\code\\\\data\\\\application\\\\data\\\\1931_2020_raw.nc'"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "raw_data = xr.open_dataset(path + \"1931_2020_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"1931_2020\")\n",
    "\n",
    "# 2021\n",
    "raw_data = xr.open_dataset(path + \"2021_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"2021\")\n",
    "\n",
    "# 2022\n",
    "raw_data = xr.open_dataset(path + \"2022_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"2022\")\n",
    "\n",
    "# 2023\n",
    "raw_data = xr.open_dataset(path + \"2023_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for CNN\n",
    "\n",
    "This section reads in the processed data and transforms it to the numpy training/testing data for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/application/data/\"\n",
    "\n",
    "# Load test data\n",
    "data_2021 = gev2frech(xr.open_dataset(path + \"2021_month_max.nc\"), year = 2021)\n",
    "data_2022 = gev2frech(xr.open_dataset(path + \"2022_month_max.nc\"), year = 2022)\n",
    "data_2023 = gev2frech(xr.open_dataset(path + \"2023_month_max.nc\"), year = 2023)\n",
    "data = xr.concat([data_2021, data_2022, data_2023], dim = \"time\")\n",
    "\n",
    "# Save data\n",
    "np.save(path + \"brown_test_data.npy\", data.pr.data)\n",
    "np.save(path + \"powexp_test_data.npy\", data.pr.data)\n",
    "data.to_netcdf(path + \"test_data.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')\n",
    "cmap_name = \"cmc.roma_r\"\n",
    "cmap = plt.get_cmap(cmap_name)\n",
    "colors = [cmap(x) for x in np.linspace(0.1,0.99,9)]\n",
    "labels = [\"June 2021\", \"July 2021\", \"August 2021\", \"June 2022\", \"July 2022\", \"August 2022\", \"June 2023\", \"July 2023\", \"August 2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powexp\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save sample predictions\n",
    "\n",
    " Save sample predictions of the energy network used for simulating processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/application/data/\"\n",
    "xr.Dataset({\"June\":xr.DataArray(cnn_es_mean[3,:]), \"July\":xr.DataArray(cnn_es_mean[4,:]), \"August\":xr.DataArray(cnn_es_mean[5,:])}).to_netcdf(path + \"parameter_estimates.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log score\n",
    "\n",
    "Calculate the log score across the models and corresponding observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_score(data, grid, model, estimation, size = 900):\n",
    "    # Log score\n",
    "    n_comb = (size*(size-1))/2\n",
    "    log_score = 0\n",
    "    for i in range(data.shape[0]-1):\n",
    "        for j in range(i+1, data.shape[0]):\n",
    "            h = euclidean(grid[:,j], grid[:,i])\n",
    "            density = bivariate_density(data[j], data[i], h, model, estimation[0], estimation[1])\n",
    "            log_score += -np.log(density)\n",
    "\n",
    "    log_score = log_score/n_comb\n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grid\n",
    "path = \"../data/application/data/\"\n",
    "grid = xr.open_dataset(path + \"grid.nc\").grid.data\n",
    "\n",
    "\n",
    "# Load test data\n",
    "grid = xr.open_dataset(path + \"grid.nc\").grid.data\n",
    "data_2021 = gev2frech(xr.open_dataset(path + \"2021_month_max.nc\"), year = 2021)\n",
    "data_2022 = gev2frech(xr.open_dataset(path + \"2022_month_max.nc\"), year = 2022)\n",
    "data_2023 = gev2frech(xr.open_dataset(path + \"2023_month_max.nc\"), year = 2023)\n",
    "data = xr.concat([data_2021, data_2022, data_2023], dim = \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brown\n",
    "model = \"brown\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)\n",
    "\n",
    "\n",
    "cnn_score = np.zeros(shape = (9))\n",
    "cnn_es_score = np.zeros(shape = (9))\n",
    "pl_score = np.zeros(shape = (9))\n",
    "for i in range(9):\n",
    "    test = data.isel(time = i).pr.data.flatten()\n",
    "    cnn_score[i] = calculate_log_score(test, grid, model, cnn[i])\n",
    "    cnn_es_score[i] = calculate_log_score(test, grid, model, cnn_es_mean[i])\n",
    "    pl_score[i] = calculate_log_score(test, grid, model, pl[i])\n",
    "print(f\"CNN: {np.round(np.mean(cnn_score), 4)}\")\n",
    "print(f\"CNN_ES: {np.round(np.mean(cnn_es_score), 4)}\")\n",
    "print(f\"PL: {np.round(np.mean(pl_score), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Desktop\\Masterarbeit\\code\\evaluation\\metrics.py:41: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  res = np.exp(-np.power((h / r), s))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN: 5.9842\n",
      "CNN_ES: 5.9792\n",
      "PL: 6.0078\n"
     ]
    }
   ],
   "source": [
    "# Powexp\n",
    "model = \"powexp\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)\n",
    "\n",
    "cnn_score = np.zeros(shape = (9))\n",
    "cnn_es_score = np.zeros(shape = (9))\n",
    "pl_score = np.zeros(shape = (9))\n",
    "for i in range(9):\n",
    "    test = data.isel(time = i).pr.data.flatten()\n",
    "    cnn_score[i] = calculate_log_score(test, grid, model, cnn[i])\n",
    "    cnn_es_score[i] = calculate_log_score(test, grid, model, cnn_es_mean[i])\n",
    "    pl_score[i] = calculate_log_score(test, grid, model, pl[i])\n",
    "print(f\"CNN: {np.round(np.mean(cnn_score), 4)}\")\n",
    "print(f\"CNN_ES: {np.round(np.mean(cnn_es_score), 4)}\")\n",
    "print(f\"PL: {np.round(np.mean(pl_score), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitmat\n",
    "model = \"whitmat\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)\n",
    "\n",
    "cnn_score = np.zeros(shape = (9))\n",
    "cnn_es_score = np.zeros(shape = (9))\n",
    "pl_score = np.zeros(shape = (9))\n",
    "for i in range(9):\n",
    "    test = data.isel(time = i).pr.data.flatten()\n",
    "    cnn_score[i] = calculate_log_score(test, grid, model, cnn[i])\n",
    "    cnn_es_score[i] = calculate_log_score(test, grid, model, cnn_es_mean[i])\n",
    "    pl_score[i] = calculate_log_score(test, grid, model, pl[i])\n",
    "print(f\"CNN: {np.round(np.mean(cnn_score), 4)}\")\n",
    "print(f\"CNN_ES: {np.round(np.mean(cnn_es_score), 4)}\")\n",
    "print(f\"PL: {np.round(np.mean(pl_score), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
