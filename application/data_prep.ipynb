{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pyresample.geometry import AreaDefinition\n",
    "from pyresample.geometry import SwathDefinition\n",
    "from pyresample import kd_tree\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pyreadr\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\")) # to import from parent directory\n",
    "from evaluation.metrics import *\n",
    "from utils import gev2frech\n",
    "import cmcrameri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data\n",
    "\n",
    "This section transforms the raw data from DWD to a lat,lon projection and interpolates the grid to the specified area across Western Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/application/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define original area\n",
    "projection = \"+proj=lcc +lat_1=35 +lat_2=65 +lat_0=52 +lon_0=10 +x_0=4000000 +y_0=2800000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"\n",
    "width = 1200\n",
    "height = 1100\n",
    "area_extent = (3500000, 2100000, 4700000, 3200000)\n",
    "area_def = AreaDefinition('original', 'Original grid', 'id', projection,width, height, area_extent)\n",
    "\n",
    "# Define target grid\n",
    "lons = np.linspace(6.38,7.48,30)\n",
    "lats = np.linspace(50.27,50.97,30)\n",
    "lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "target_grid = SwathDefinition(lons = lon2d, lats = lat2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for projection, interpolation and monthly maximum\n",
    "def downsample(data, area_def, target_grid):\n",
    "    result = kd_tree.resample_nearest(\n",
    "        area_def, data, target_grid, radius_of_influence=50000, epsilon=0.5\n",
    "    )\n",
    "    return result\n",
    "\n",
    "def xr_downsample(data, area_def, target_grid):\n",
    "    result = xr.apply_ufunc(\n",
    "        downsample,\n",
    "        data,\n",
    "        area_def,\n",
    "        target_grid,\n",
    "        input_core_dims=[[\"y\", \"x\", \"time\"], [], []],\n",
    "        output_core_dims=[[\"y\", \"x\", \"time\"]],\n",
    "        exclude_dims=set((\"x\", \"y\")),\n",
    "        vectorize = True,\n",
    "        dask = \"allowed\"\n",
    "    )\n",
    "    return result.max(dim = [\"time\"])\n",
    "\n",
    "def transform_data(data, area_def, target_grid, year = \"\"):\n",
    "    transformed_data = data.resample(time = \"1MS\").apply(xr_downsample, args = (area_def, target_grid))\n",
    "    transformed_data = transformed_data.isel(time=(transformed_data.time.dt.month.isin([6,7,8])))\n",
    "    xr.Dataset({\"pr\":transformed_data}).to_netcdf(f\"../../data/application/{year}_month_max.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "raw_data = xr.open_dataset(path + \"1931_2020_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"1931_2020\")\n",
    "\n",
    "# 2021\n",
    "raw_data = xr.open_dataset(path + \"2021_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"2021\")\n",
    "\n",
    "# 2022\n",
    "raw_data = xr.open_dataset(path + \"2022_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"2022\")\n",
    "\n",
    "# 2023\n",
    "raw_data = xr.open_dataset(path + \"2023_raw.nc\")\n",
    "data = raw_data.pr.isel(time=(raw_data.time.dt.month.isin([6,7,8])))\n",
    "transform_data(data, area_def, target_grid, year = \"2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for CNN\n",
    "\n",
    "This section reads in the processed data and transforms it to the numpy training/testing data for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/application/data/\"\n",
    "\n",
    "# Load test data\n",
    "data_2021 = gev2frech(xr.open_dataset(path + \"2021_month_max.nc\"), year = 2021)\n",
    "data_2022 = gev2frech(xr.open_dataset(path + \"2022_month_max.nc\"), year = 2022)\n",
    "data_2023 = gev2frech(xr.open_dataset(path + \"2023_month_max.nc\"), year = 2023)\n",
    "data = xr.concat([data_2021, data_2022, data_2023], dim = \"time\")\n",
    "\n",
    "# Save data\n",
    "np.save(path + \"brown_test_data.npy\", data.pr.data)\n",
    "np.save(path + \"powexp_test_data.npy\", data.pr.data)\n",
    "data.to_netcdf(path + \"test_data.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')\n",
    "cmap_name = \"cmc.roma_r\"\n",
    "cmap = plt.get_cmap(cmap_name)\n",
    "colors = [cmap(x) for x in np.linspace(0.1,0.99,9)]\n",
    "labels = [\"June 2021\", \"July 2021\", \"August 2021\", \"June 2022\", \"July 2022\", \"August 2022\", \"June 2023\", \"July 2023\", \"August 2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powexp\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save sample predictions\n",
    "\n",
    " Save sample predictions of the energy network used for simulating processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/application/data/\"\n",
    "xr.Dataset({\"June\":xr.DataArray(cnn_es_mean[3,:]), \"July\":xr.DataArray(cnn_es_mean[4,:]), \"August\":xr.DataArray(cnn_es_mean[5,:])}).to_netcdf(path + \"parameter_estimates.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log score\n",
    "\n",
    "Calculate the log score across the models and corresponding observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_score(data, grid, model, estimation, size = 900):\n",
    "    # Log score\n",
    "    n_comb = (size*(size-1))/2\n",
    "    log_score = 0\n",
    "    for i in range(data.shape[0]-1):\n",
    "        for j in range(i+1, data.shape[0]):\n",
    "            h = euclidean(grid[:,j], grid[:,i])\n",
    "            density = bivariate_density(data[j], data[i], h, model, estimation[0], estimation[1])\n",
    "            log_score += -np.log(density)\n",
    "\n",
    "    log_score = log_score/n_comb\n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grid\n",
    "path = \"../data/application/data/\"\n",
    "grid = xr.open_dataset(path + \"grid.nc\").grid.data\n",
    "\n",
    "\n",
    "# Load test data\n",
    "grid = xr.open_dataset(path + \"grid.nc\").grid.data\n",
    "data_2021 = gev2frech(xr.open_dataset(path + \"2021_month_max.nc\"), year = 2021)\n",
    "data_2022 = gev2frech(xr.open_dataset(path + \"2022_month_max.nc\"), year = 2022)\n",
    "data_2023 = gev2frech(xr.open_dataset(path + \"2023_month_max.nc\"), year = 2023)\n",
    "data = xr.concat([data_2021, data_2022, data_2023], dim = \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brown\n",
    "model = \"brown\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)\n",
    "\n",
    "\n",
    "cnn_score = np.zeros(shape = (9))\n",
    "cnn_es_score = np.zeros(shape = (9))\n",
    "pl_score = np.zeros(shape = (9))\n",
    "for i in range(9):\n",
    "    test = data.isel(time = i).pr.data.flatten()\n",
    "    cnn_score[i] = calculate_log_score(test, grid, model, cnn[i])\n",
    "    cnn_es_score[i] = calculate_log_score(test, grid, model, cnn_es_mean[i])\n",
    "    pl_score[i] = calculate_log_score(test, grid, model, pl[i])\n",
    "print(f\"CNN: {np.round(np.mean(cnn_score), 4)}\")\n",
    "print(f\"CNN_ES: {np.round(np.mean(cnn_es_score), 4)}\")\n",
    "print(f\"PL: {np.round(np.mean(pl_score), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Powexp\n",
    "model = \"powexp\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)\n",
    "\n",
    "cnn_score = np.zeros(shape = (9))\n",
    "cnn_es_score = np.zeros(shape = (9))\n",
    "pl_score = np.zeros(shape = (9))\n",
    "for i in range(9):\n",
    "    test = data.isel(time = i).pr.data.flatten()\n",
    "    cnn_score[i] = calculate_log_score(test, grid, model, cnn[i])\n",
    "    cnn_es_score[i] = calculate_log_score(test, grid, model, cnn_es_mean[i])\n",
    "    pl_score[i] = calculate_log_score(test, grid, model, pl[i])\n",
    "print(f\"CNN: {np.round(np.mean(cnn_score), 4)}\")\n",
    "print(f\"CNN_ES: {np.round(np.mean(cnn_es_score), 4)}\")\n",
    "print(f\"PL: {np.round(np.mean(pl_score), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitmat\n",
    "model = \"whitmat\"\n",
    "pl = pyreadr.read_r(f\"../data/application/results/{model}_pl.RData\")[\"results\"].to_numpy()[:,0:2]\n",
    "cnn = np.load(f\"../data/application/results/{model}_cnn.npy\")\n",
    "cnn_es = np.load(f\"../data/application/results/{model}_cnn_es.npy\")\n",
    "cnn_es_mean = cnn_es.mean(axis = 2)\n",
    "\n",
    "cnn_score = np.zeros(shape = (9))\n",
    "cnn_es_score = np.zeros(shape = (9))\n",
    "pl_score = np.zeros(shape = (9))\n",
    "for i in range(9):\n",
    "    test = data.isel(time = i).pr.data.flatten()\n",
    "    cnn_score[i] = calculate_log_score(test, grid, model, cnn[i])\n",
    "    cnn_es_score[i] = calculate_log_score(test, grid, model, cnn_es_mean[i])\n",
    "    pl_score[i] = calculate_log_score(test, grid, model, pl[i])\n",
    "print(f\"CNN: {np.round(np.mean(cnn_score), 4)}\")\n",
    "print(f\"CNN_ES: {np.round(np.mean(cnn_es_score), 4)}\")\n",
    "print(f\"PL: {np.round(np.mean(pl_score), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
