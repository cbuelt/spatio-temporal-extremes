{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d074e320-f7f9-4bde-a42a-4d86c1811ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyreadr\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\")) # to import from parent directory\n",
    "from utils.utils import generate_support_points\n",
    "from evaluation.metrics import extremal_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0866f08-76e7-4b76-8bd6-31b055d92c7f",
   "metadata": {},
   "source": [
    "# Save Single model\n",
    "\n",
    "By specifying the model and path, one can transform simulations from the R.script into corresponding numpy files, useable for pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3194f2bf-76f4-4e6d-b5e4-4956e035ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"application\"\n",
    "path = f'../data/{dir}/data/'\n",
    "# Image size\n",
    "img_size = 30\n",
    "models = [\"brown\", \"powexp\", \"whitmat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d9d34",
   "metadata": {},
   "source": [
    "## Transform train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6cb2aa6-4f07-4d2e-a49b-796529bd34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val split\n",
    "split = 4000\n",
    "\n",
    "for model in models:\n",
    "    params = pyreadr.read_r(path+f\"{model}_train_params.RData\")[\"train_params\"]\n",
    "    data = pyreadr.read_r(path+f\"{model}_train_data.RData\")[\"train_data\"].to_numpy()\n",
    "    #Train/val\n",
    "    train_params = params.loc[0:(split-1),].to_numpy()\n",
    "    val_params =params.loc[split:,].to_numpy()\n",
    "    train_data =data[:,0:split]\n",
    "    train_data = np.reshape(np.swapaxes(train_data, 0,1), newshape = (-1, img_size, img_size))\n",
    "    val_data = data[:,split:]\n",
    "    val_data = np.reshape(np.swapaxes(val_data, 0,1), newshape = (-1, img_size, img_size))\n",
    "    \n",
    "    np.save(path+f\"{model}_train_params\", train_params)\n",
    "    np.save(path+f\"{model}_val_params\", val_params)\n",
    "    np.save(path+f\"{model}_train_data\", train_data)\n",
    "    np.save(path+f\"{model}_val_data\", val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81229939",
   "metadata": {},
   "source": [
    "## Transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530538b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    test_params = pyreadr.read_r(path+f\"{model}_test_params.RData\")[\"test_params\"].to_numpy()\n",
    "    test_data = pyreadr.read_r(path+f\"{model}_test_data.RData\")[\"test_data\"].to_numpy()\n",
    "    test_data = np.reshape(np.swapaxes(test_data, 0,1), newshape = (-1, img_size, img_size))\n",
    "\n",
    "    np.save(path+f\"{model}_test_params\", test_params)\n",
    "    np.save(path+f\"{model}_test_data\", test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd418332",
   "metadata": {},
   "source": [
    "# Save aggregated model\n",
    "\n",
    "Put several models together for training data and save them as one. For this case, one also needs to extract the extremeal coefficient function beforehand. The test data stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27b6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"application\"\n",
    "path = f'../data/{dir}/data/'\n",
    "# Image size\n",
    "img_size = 30\n",
    "models = [\"brown\", \"powexp\", \"whitmat\"]\n",
    "\n",
    "# Parameters for extremal coefficient function\n",
    "h_support = generate_support_points(dh = 0.1, max_length = 42.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38bbaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val split (individual per model)\n",
    "test_size = 5000\n",
    "split = 4000\n",
    "n_models = len(models)\n",
    "\n",
    "train_params = np.zeros((split * n_models, 2))\n",
    "val_params = np.zeros(((test_size - split) * n_models, 2))\n",
    "train_data = np.zeros((split * n_models, img_size, img_size))\n",
    "val_data = np.zeros(((test_size - split) * n_models, img_size, img_size))\n",
    "train_ext_coef = np.zeros((split * n_models, len(h_support)))\n",
    "val_ext_coef = np.zeros(((test_size - split) * n_models, len(h_support)))\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    # Generate data and parameters\n",
    "    params = pyreadr.read_r(path+f\"{model}_train_params.RData\")[\"train_params\"]\n",
    "    data = pyreadr.read_r(path+f\"{model}_train_data.RData\")[\"train_data\"].to_numpy()\n",
    "    #Train/val\n",
    "    train_params[i*split:(i+1)*split] = params.to_numpy()[0:split]\n",
    "    val_params[i*(test_size -split):(i+1)*(test_size-split)] = params.to_numpy()[split:,]\n",
    "    train_data[i*split:(i+1)*split,:,:] = np.reshape(np.swapaxes(data[:,0:split], 0,1), newshape = (-1, img_size, img_size))\n",
    "    val_data[i*(test_size -split):(i+1)*(test_size-split),:,:] = np.reshape(np.swapaxes(data[:,split:], 0,1), newshape = (-1, img_size, img_size))\n",
    "\n",
    "    # Calculate extremal coefficient function\n",
    "    train_ext_coef[i*split:(i+1)*split] = extremal_coefficient(h = h_support, model = model, r = params.to_numpy()[0:split,0], s = params.to_numpy()[0:split,1])\n",
    "    val_ext_coef[i*(test_size -split):(i+1)*(test_size-split)] = extremal_coefficient(h = h_support, model = model, r = params.to_numpy()[split:,0], s = params.to_numpy()[split:,1])\n",
    "    \n",
    "np.save(path+f\"aggregated_train_params\", train_params)\n",
    "np.save(path+f\"aggregated_val_params\", val_params)\n",
    "np.save(path+f\"aggregated_train_data\", train_data)\n",
    "np.save(path+f\"aggregated_val_data\", val_data)\n",
    "np.save(path+f\"aggregated_train_ext_coef\", train_ext_coef)\n",
    "np.save(path+f\"aggregated_val_ext_coef\", val_ext_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec7886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
